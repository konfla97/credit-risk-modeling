{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3667b-38e6-4669-926d-f0d68cbb4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Import required libraries and define project paths\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d593e0-6a64-4f12-a109-719dcb5b843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Load the Home Credit training dataset\n",
    "\n",
    "PROJECT_DIR = Path(\"~/Documents/credit-scoring-home-credit\").expanduser()\n",
    "DATA_RAW = PROJECT_DIR / \"data\" / \"raw\"\n",
    "\n",
    "train_path = DATA_RAW / \"application_train.csv\"\n",
    "\n",
    "df = pd.read_csv(train_path, low_memory=False)\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debeddd6-0bbc-4f52-8545-3f8a8e554225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Preview the first few rows of the dataset\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379f289-5fc5-4081-a2f8-6577febb45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ Examine the target distribution (class imbalance check)\n",
    "\n",
    "target_counts = df[\"TARGET\"].value_counts()\n",
    "target_rate = df[\"TARGET\"].value_counts(normalize=True)\n",
    "\n",
    "target_counts, target_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c8502-08ce-49e1-bd0d-f16b69e9812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5Ô∏è‚É£ Demonstrate why accuracy is misleading in imbalanced datasets\n",
    "\n",
    "# Simulate a naive model that predicts everyone as non-default\n",
    "y_true = df[\"TARGET\"].values\n",
    "y_pred_all_zero = np.zeros_like(y_true)\n",
    "\n",
    "accuracy_all_zero = (y_pred_all_zero == y_true).mean()\n",
    "default_recall_all_zero = (\n",
    "    ((y_pred_all_zero == 1) & (y_true == 1)).sum()\n",
    "    / max((y_true == 1).sum(), 1)\n",
    ")\n",
    "\n",
    "accuracy_all_zero, default_recall_all_zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c9024-c786-43f9-a91a-e2cdf3cec160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6Ô∏è‚É£ Inspect data types (numeric vs categorical overview)\n",
    "\n",
    "df.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cb531-bac2-4ae3-8e2d-b390eb038a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7Ô∏è‚É£ Calculate percentage of missing values per column (top 25)\n",
    "\n",
    "missing_pct = df.isna().mean().sort_values(ascending=False) * 100\n",
    "missing_pct.head(25).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2491ca4-749b-4ea3-bf21-e3e23b8bcaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8Ô∏è‚É£ Count how many columns exceed different missingness thresholds\n",
    "\n",
    "thresholds = [10, 20, 40, 60, 80]\n",
    "missing_summary = {t: (missing_pct > t).sum() for t in thresholds}\n",
    "\n",
    "missing_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5c0df-651a-4a75-9872-28f17ba0fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9Ô∏è‚É£ Generate summary statistics for numeric variables\n",
    "\n",
    "df.describe().T[[\"mean\", \"std\", \"min\", \"max\"]].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60f9e2-a8e8-48dc-96f5-7be17e08a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîü Separate numeric and categorical columns for later analysis\n",
    "\n",
    "num_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "len(num_cols), len(cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2267276-dbc0-4bc8-b636-532c790d2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£1Ô∏è‚É£ Analyze default rate by a categorical feature (example: CODE_GENDER)\n",
    "\n",
    "col = \"CODE_GENDER\"\n",
    "\n",
    "default_by_gender = (\n",
    "    df.groupby(col)[\"TARGET\"]\n",
    "    .agg(default_rate=\"mean\", count=\"size\")\n",
    "    .sort_values(\"default_rate\", ascending=False)\n",
    ")\n",
    "\n",
    "default_by_gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f6f5c-5e27-4cc4-9bfc-70a2d005c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£2Ô∏è‚É£ Compare a numeric variable across default vs non-default borrowers (example: AMT_INCOME_TOTAL)\n",
    "\n",
    "col = \"AMT_INCOME_TOTAL\"\n",
    "\n",
    "df.groupby(\"TARGET\")[col].describe()[[\"mean\", \"50%\", \"std\", \"min\", \"max\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63bb69-b0c7-4104-b39d-3853559bfa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£3Ô∏è‚É£ Compute correlation of numeric features with TARGET\n",
    "\n",
    "num_df = df[num_cols].copy()\n",
    "\n",
    "corr_with_target = (\n",
    "    num_df.corr(numeric_only=True)[\"TARGET\"]\n",
    "    .drop(\"TARGET\")\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "corr_with_target.head(10), corr_with_target.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f883fd5-00b0-49fc-a7f3-2f3b655765ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£4Ô∏è‚É£ Identify columns with more than 60% missing\n",
    "\n",
    "missing_pct = df.isna().mean()\n",
    "\n",
    "high_missing_cols = missing_pct[missing_pct > 0.6].index.tolist()\n",
    "\n",
    "len(high_missing_cols), high_missing_cols[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dbb8b0-dbdb-4708-b962-9bb9a39aba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£5Ô∏è‚É£ Check if missingness predicts default\n",
    "\n",
    "missing_analysis = []\n",
    "\n",
    "for col in high_missing_cols:\n",
    "    \n",
    "    temp = pd.DataFrame({\n",
    "        \"is_missing\": df[col].isna().astype(int),\n",
    "        \"TARGET\": df[\"TARGET\"]\n",
    "    })\n",
    "    \n",
    "    grouped = temp.groupby(\"is_missing\")[\"TARGET\"].mean()\n",
    "    \n",
    "    if len(grouped) == 2:  # both missing and non-missing exist\n",
    "        missing_analysis.append({\n",
    "            \"column\": col,\n",
    "            \"default_rate_not_missing\": grouped[0],\n",
    "            \"default_rate_missing\": grouped[1],\n",
    "            \"difference\": grouped[1] - grouped[0]\n",
    "        })\n",
    "\n",
    "missing_df = pd.DataFrame(missing_analysis).sort_values(\"difference\", ascending=False)\n",
    "\n",
    "missing_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e209b3-e5d4-4f27-8b61-12c685841655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£6Ô∏è‚É£ Identify high-missing columns (>60%)\n",
    "\n",
    "missing_pct = df.isna().mean()\n",
    "\n",
    "high_missing_cols = missing_pct[missing_pct > 0.6].index.tolist()\n",
    "\n",
    "len(high_missing_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649732f0-e94d-45d2-a59b-b89f1dfbc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£7Ô∏è‚É£ Create missing indicator features\n",
    "\n",
    "df_enhanced = df.copy()\n",
    "\n",
    "for col in high_missing_cols:\n",
    "    indicator_name = col + \"_MISSING\"\n",
    "    df_enhanced[indicator_name] = df[col].isna().astype(int)\n",
    "\n",
    "df_enhanced[[high_missing_cols[0], high_missing_cols[0] + \"_MISSING\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e907a7-32e9-419f-b3dc-d77fd6c2d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£8Ô∏è‚É£ Drop raw columns with >60% missing\n",
    "\n",
    "df_enhanced = df_enhanced.drop(columns=high_missing_cols)\n",
    "\n",
    "df_enhanced.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7534c0-c09b-4560-ae20-df1726eb3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£9Ô∏è‚É£ Recompute missingness after cleaning\n",
    "\n",
    "missing_after = df_enhanced.isna().mean().sort_values(ascending=False) * 100\n",
    "missing_after.head(20).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c04ce-5427-4b95-be68-f88d022ce614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£0Ô∏è‚É£ Remove redundant _MEDI and _MODE versions (keep _AVG only)\n",
    "\n",
    "cols_to_drop_redundant = [\n",
    "    col for col in df_enhanced.columns\n",
    "    if col.endswith(\"_MEDI\") or col.endswith(\"_MODE\")\n",
    "]\n",
    "\n",
    "len(cols_to_drop_redundant)\n",
    "df_enhanced = df_enhanced.drop(columns=cols_to_drop_redundant)\n",
    "\n",
    "df_enhanced.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196c17f-fc99-4033-b6e8-d0f3b80d880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_enhanced.isna().mean().sort_values(ascending=False) * 100).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24802a1b-e7c5-4454-af5d-f6fd98432412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£1Ô∏è‚É£ Drop remaining high-missing property features (>45%) except EXT_SOURCE and OCCUPATION_TYPE\n",
    "\n",
    "cols_to_keep_even_if_missing = [\n",
    "    \"EXT_SOURCE_1\",\n",
    "    \"EXT_SOURCE_3\",\n",
    "    \"OCCUPATION_TYPE\"\n",
    "]\n",
    "\n",
    "remaining_missing = df_enhanced.isna().mean()\n",
    "\n",
    "cols_to_drop_high_missing = [\n",
    "    col for col in remaining_missing[remaining_missing > 0.45].index\n",
    "    if col not in cols_to_keep_even_if_missing\n",
    "]\n",
    "\n",
    "len(cols_to_drop_high_missing)\n",
    "df_enhanced = df_enhanced.drop(columns=cols_to_drop_high_missing)\n",
    "\n",
    "df_enhanced.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e995668-a585-4a50-b634-9d6152121c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_enhanced.isna().mean().sort_values(ascending=False) * 100).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a4941-0d94-473e-801c-7aa606f4d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£1Ô∏è‚É£.5Ô∏è‚É£ Fix DAYS_EMPLOYED anomaly (365243 means missing)\n",
    "\n",
    "df_enhanced[\"DAYS_EMPLOYED\"] = df_enhanced[\"DAYS_EMPLOYED\"].replace(365243, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a67c5-c41c-4b4c-8180-70203096f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£2Ô∏è‚É£ Prepare features and target\n",
    "\n",
    "X = df_enhanced.drop(columns=[\"TARGET\"])\n",
    "y = df_enhanced[\"TARGET\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a3248-471c-4b52-9ca6-caf3b822ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£3Ô∏è‚É£ Train / validation split (stratified)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_valid.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f82dc-21af-4d22-9413-2494bc036c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£4Ô∏è‚É£ Separate numeric and categorical columns\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "len(num_cols), len(cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1f503-8555-42e0-93f0-52fcc5dc7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£5Ô∏è‚É£ Build preprocessing pipeline (impute + scale numeric, impute + one-hot categorical)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Numeric: median impute + standardize (helps logistic regression converge)\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical: most-frequent impute + one-hot encode\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine numeric + categorical preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipeline, num_cols),\n",
    "        (\"cat\", categorical_pipeline, cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af9649-9330-4363-b7ce-d57e1b0e3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£6Ô∏è‚É£ Define logistic regression model (baseline PD model)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "logit_model = LogisticRegression(\n",
    "    max_iter=3000,          # increased to help convergence\n",
    "    class_weight=\"balanced\",# handle class imbalance\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "\n",
    "# Full pipeline = preprocessing + model\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", logit_model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7404b-18c7-46dc-8329-060b8620f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£7Ô∏è‚É£ Train the model on the training set\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3703b2da-4b56-4672-b72c-8ed57899bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£8Ô∏è‚É£ Predict PD (probability of default) on validation set and compute ROC-AUC / PR-AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# Predicted probability of default (PD)\n",
    "p_valid = clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_valid, p_valid)\n",
    "pr_auc = average_precision_score(y_valid, p_valid)\n",
    "\n",
    "roc_auc, pr_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7b14b-9297-4d22-bfa1-e9970229aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£9Ô∏è‚É£ Confusion matrix at a default threshold of 0.50 (for illustration only)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_05 = (p_valid >= 0.5).astype(int)\n",
    "confusion_matrix(y_valid, pred_05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4678403-0b91-4aa4-af31-96a0a5ccbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£0Ô∏è‚É£ Classification report at threshold 0.50 (precision/recall for default class)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_valid, pred_05, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6366cc-e57a-4e0f-8314-9dcbb67e5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£1Ô∏è‚É£ Plot ROC curve and PR curve (visual model performance)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_valid, p_valid)\n",
    "plt.title(\"ROC Curve (Validation)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "PrecisionRecallDisplay.from_predictions(y_valid, p_valid)\n",
    "plt.title(\"Precision-Recall Curve (Validation)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13251f57-76d9-48f2-873d-3c7cfbfbd52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£2Ô∏è‚É£ Calibration curve (are predicted PDs aligned with observed default rates?)\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"~/Documents/credit-scoring-home-credit\").expanduser()\n",
    "PLOTS_DIR = PROJECT_DIR / \"plots\"\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PLOTS_DIR\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "frac_pos, mean_pred = calibration_curve(y_valid, p_valid, n_bins=10)\n",
    "\n",
    "\n",
    "plt.plot(mean_pred, frac_pos, marker=\"o\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"Mean Predicted PD\")\n",
    "plt.ylabel(\"Observed Default Rate\")\n",
    "plt.title(\"Calibration Curve (Validation)\")\n",
    "plt.savefig(PLOTS_DIR / \"calibration_curve_validation.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6a749-ae16-4e3f-af33-3303905e864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£3Ô∏è‚É£ Compute KS statistic (common in credit risk)\n",
    "\n",
    "# KS = max difference between CDFs of scores for good vs bad\n",
    "import numpy as np\n",
    "\n",
    "def ks_statistic(y_true, y_score, n_bins=100):\n",
    "    data = pd.DataFrame({\"y\": y_true, \"score\": y_score}).sort_values(\"score\")\n",
    "    data[\"bin\"] = pd.qcut(data[\"score\"], q=n_bins, duplicates=\"drop\")\n",
    "    \n",
    "    grouped = data.groupby(\"bin\")[\"y\"]\n",
    "    bad_rate = grouped.mean()\n",
    "    total = grouped.size()\n",
    "    \n",
    "    bad_cum = (bad_rate * total).cumsum() / (data[\"y\"].sum())\n",
    "    good_cum = ((1 - bad_rate) * total).cumsum() / ((1 - data[\"y\"]).sum())\n",
    "    \n",
    "    ks = np.max(np.abs(bad_cum - good_cum))\n",
    "    return ks\n",
    "\n",
    "ks = ks_statistic(y_valid, p_valid)\n",
    "ks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1226c-d59e-47cc-b9e3-013e53bc9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£4Ô∏è‚É£ Extract logistic regression coefficients and compute odds ratios\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "feature_names = clf.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = clf.named_steps[\"model\"].coef_[0]\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coefficient\": coefficients,\n",
    "    \"odds_ratio\": np.exp(coefficients)\n",
    "})\n",
    "\n",
    "coef_df_sorted = coef_df.sort_values(\"coefficient\")\n",
    "\n",
    "coef_df_sorted.head(10), coef_df_sorted.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f2894-1306-4840-a4f5-3ec7056b73e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (creditrisk311)",
   "language": "python",
   "name": "creditrisk311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
